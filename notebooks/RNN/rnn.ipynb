{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, LSTM, TimeDistributed\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "\n",
    "import matplotlib\n",
    "# matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "# import collections\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, LSTM, TimeDistributed\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "\n",
    "\n",
    "def getData(meta, X_raw, tgt, future):\n",
    "\t\"\"\"\n",
    "\tLet us say that target 'tgt' is the index of a tile, \n",
    "\tso we predict for all three variables, CASE\n",
    "\t\"\"\"\n",
    "\t\n",
    "\tAR = meta.loc[tgt, 'CASE']\n",
    "\t#PR = meta.loc[tgt, 'BURGLARY-THEFT-MOTOR_VEHICLE_THEFT']\n",
    "\t#AS = meta.loc[tgt, 'HOMICIDE-ASSAULT-BATTERY']\n",
    "\t\n",
    "\t#print('Arrest: {},\\nProperty: {},\\nAssault: {}.'.format(AR, PR, AS))\n",
    "\t\n",
    "\tX = X_raw.T\n",
    "\tY = X_raw[[AR]].T\n",
    "\n",
    "\t# get train and test\n",
    "\t# Train is the first two years (2014, 2015), so of length 365 * 2 = 730\n",
    "\t# test is the last year (2016, a leap year), so of length 366\n",
    "\tX_train = X[:30 - future]\n",
    "\tY_train = Y[future: 30]\n",
    "\n",
    "\tX_test = X[30 - future: -future]\n",
    "\tY_test = Y[30:]\n",
    "\t\n",
    "\t# Reshape to fit RNN\n",
    "\t# The dimension of RNN input/output is (num_samples, length_in_time, data_dimension)\n",
    "\tX_train = X_train.reshape(1, *X_train.shape)\n",
    "\tY_train = Y_train.reshape(1, *Y_train.shape)\n",
    "\n",
    "\tX_test = X_test.reshape(1, *X_test.shape)\n",
    "\tY_test = Y_test.reshape(1, *Y_test.shape)\n",
    "\t\n",
    "\tprint('Training data: input dim = {}, output dim = {}'.format(X_train.shape, Y_train.shape))\n",
    "\tprint('Out-sample data: input dim = {}, output dim = {}'.format(X_test.shape, Y_test.shape))\n",
    "\n",
    "\treturn X_train, Y_train, X_test, Y_test\n",
    "\n",
    "\n",
    "def train(X_train, Y_train, epochs=200):\n",
    "\n",
    "\tmodel = tf.keras.Sequential()\n",
    "\n",
    "\t# Don't use unless you are sure test length is the same\n",
    "\t# as the train length, which is not the case for us\n",
    "\t# model.add(tf.keras.Input(X_train.shape[1:]))  \n",
    "\n",
    "\t# Two LSTM layers\n",
    "\tmodel.add(LSTM(units=30, input_shape=(None, X_train.shape[-1]), return_sequences=True))\n",
    "\tmodel.add(LSTM(units=10, return_sequences=True))\n",
    "\t\n",
    "\t# One output layers\n",
    "\tmodel.add(TimeDistributed(Dense(units=1, activation='sigmoid')))\n",
    "\t\n",
    "\tmodel.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "\tmodel.summary()\n",
    "\n",
    "\tmodel.fit(X_train, Y_train, epochs=epochs, batch_size=1, verbose=1)\n",
    "\t\n",
    "\treturn model\n",
    "\n",
    "\n",
    "def train_3(X_train, Y_train, epochs=200):\n",
    "\n",
    "\tmodel = tf.keras.Sequential()\n",
    "\n",
    "\t# Don't use unless you are sure test length is the same\n",
    "\t# as the train length, which is not the case for us\n",
    "\t# model.add(tf.keras.Input(X_train.shape[1:]))  \n",
    "\n",
    "\t# Two LSTM layers\n",
    "\tmodel.add(LSTM(units=50, input_shape=(None, X_train.shape[-1]), return_sequences=True))\n",
    "\tmodel.add(LSTM(units=10, return_sequences=True))\n",
    "\tmodel.add(LSTM(units=10, return_sequences=True))\n",
    "\t\n",
    "\t# One output layers\n",
    "\tmodel.add(TimeDistributed(Dense(units=1, activation='sigmoid')))\n",
    "\t\n",
    "\tmodel.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "\tmodel.summary()\n",
    "\n",
    "\tmodel.fit(X_train, Y_train, epochs=epochs, batch_size=1, verbose=1)\n",
    "\t\n",
    "\treturn model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#meta = pd.read_csv('meta.csv', index_col=0)\n",
    "meta = pd.read_csv('meta2.csv', index_col=0)\n",
    "#X_raw = np.genfromtxt('CRIME-_2014-01-01_2016-12-31.csv')\n",
    "X_raw = np.genfromtxt('/home/ishanu/Dropbox/ZED/Research/CCTS40500_/notebooks/time_series_covid/data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CASE</th>\n",
       "      <th>lat1</th>\n",
       "      <th>lat1.1</th>\n",
       "      <th>lon1</th>\n",
       "      <th>lon2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31.82571#117.2264#CASE</th>\n",
       "      <td>1</td>\n",
       "      <td>31.82571</td>\n",
       "      <td>31.82571</td>\n",
       "      <td>117.2264</td>\n",
       "      <td>117.2264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40.18238#116.4142#CASE</th>\n",
       "      <td>2</td>\n",
       "      <td>40.18238</td>\n",
       "      <td>40.18238</td>\n",
       "      <td>116.4142</td>\n",
       "      <td>116.4142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30.05718#107.874#CASE</th>\n",
       "      <td>3</td>\n",
       "      <td>30.05718</td>\n",
       "      <td>30.05718</td>\n",
       "      <td>107.8740</td>\n",
       "      <td>107.8740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26.07783#117.9895#CASE</th>\n",
       "      <td>4</td>\n",
       "      <td>26.07783</td>\n",
       "      <td>26.07783</td>\n",
       "      <td>117.9895</td>\n",
       "      <td>117.9895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36.0611#103.8343#CASE</th>\n",
       "      <td>5</td>\n",
       "      <td>36.06110</td>\n",
       "      <td>36.06110</td>\n",
       "      <td>103.8343</td>\n",
       "      <td>103.8343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50.5039#4.4699#CASE</th>\n",
       "      <td>70</td>\n",
       "      <td>50.50390</td>\n",
       "      <td>50.50390</td>\n",
       "      <td>4.4699</td>\n",
       "      <td>4.4699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43.0731#-89.4012#CASE</th>\n",
       "      <td>71</td>\n",
       "      <td>43.07310</td>\n",
       "      <td>43.07310</td>\n",
       "      <td>-89.4012</td>\n",
       "      <td>-89.4012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35.4437#129.638#CASE</th>\n",
       "      <td>72</td>\n",
       "      <td>35.44370</td>\n",
       "      <td>35.44370</td>\n",
       "      <td>129.6380</td>\n",
       "      <td>129.6380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32.7157#-117.1611#CASE</th>\n",
       "      <td>73</td>\n",
       "      <td>32.71570</td>\n",
       "      <td>32.71570</td>\n",
       "      <td>-117.1611</td>\n",
       "      <td>-117.1611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29.4241#-98.4936#CASE</th>\n",
       "      <td>74</td>\n",
       "      <td>29.42410</td>\n",
       "      <td>29.42410</td>\n",
       "      <td>-98.4936</td>\n",
       "      <td>-98.4936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        CASE      lat1    lat1.1      lon1      lon2\n",
       "31.82571#117.2264#CASE     1  31.82571  31.82571  117.2264  117.2264\n",
       "40.18238#116.4142#CASE     2  40.18238  40.18238  116.4142  116.4142\n",
       "30.05718#107.874#CASE      3  30.05718  30.05718  107.8740  107.8740\n",
       "26.07783#117.9895#CASE     4  26.07783  26.07783  117.9895  117.9895\n",
       "36.0611#103.8343#CASE      5  36.06110  36.06110  103.8343  103.8343\n",
       "...                      ...       ...       ...       ...       ...\n",
       "50.5039#4.4699#CASE       70  50.50390  50.50390    4.4699    4.4699\n",
       "43.0731#-89.4012#CASE     71  43.07310  43.07310  -89.4012  -89.4012\n",
       "35.4437#129.638#CASE      72  35.44370  35.44370  129.6380  129.6380\n",
       "32.7157#-117.1611#CASE    73  32.71570  32.71570 -117.1611 -117.1611\n",
       "29.4241#-98.4936#CASE     74  29.42410  29.42410  -98.4936  -98.4936\n",
       "\n",
       "[74 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cynetTop = meta.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74, 45)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_raw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ishanu/.local/lib/python3.7/site-packages/pandas/core/indexing.py:961: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return getattr(section, self.name)[new_key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: input dim = (1, 28, 74), output dim = (1, 28, 1)\n",
      "Out-sample data: input dim = (1, 15, 74), output dim = (1, 15, 1)\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_15 (LSTM)               (None, None, 30)          12600     \n",
      "_________________________________________________________________\n",
      "lstm_16 (LSTM)               (None, None, 10)          1640      \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, None, 1)           11        \n",
      "=================================================================\n",
      "Total params: 14,251\n",
      "Trainable params: 14,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 2s 2s/sample - loss: 22212.4551\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 35ms/sample - loss: 22209.2090\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 32ms/sample - loss: 22205.0723\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 29ms/sample - loss: 22201.2969\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 31ms/sample - loss: 22198.4863\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 34ms/sample - loss: 22196.1699\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 37ms/sample - loss: 22194.1211\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 36ms/sample - loss: 22192.1523\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 33ms/sample - loss: 22190.1113\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 39ms/sample - loss: 22188.0449\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 38ms/sample - loss: 22185.8086\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 30ms/sample - loss: 22183.5977\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 32ms/sample - loss: 22181.4668\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 33ms/sample - loss: 22179.3145\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 36ms/sample - loss: 22177.0215\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 36ms/sample - loss: 22174.8281\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 37ms/sample - loss: 22172.6836\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 37ms/sample - loss: 22170.6387\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 37ms/sample - loss: 22168.6113\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 35ms/sample - loss: 22166.6074\n"
     ]
    }
   ],
   "source": [
    "center = cynetTop[0]\n",
    "tile = meta.loc[center, ['lat1', 'lat2','lon1', 'lon2']]\n",
    "    \n",
    "future = 2\n",
    "    \n",
    "X_train, Y_train, X_test, Y_test = getData(meta, X_raw, center, future)\n",
    "\n",
    "model = train(X_train, Y_train, epochs=20)\n",
    "prediction = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "figTitle = '#'.join(map(str, tile.values)) + '_{}'.format(future)\n",
    "dfName = figTitle + '.rnnres'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test=np.squeeze(Y_test)\n",
    "prediction=np.squeeze(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.84280627],\n",
       "       [0.84280627, 1.        ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "np.corrcoef(Y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
