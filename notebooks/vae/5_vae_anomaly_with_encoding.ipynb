{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ishanu/.local/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-03 10:29:11.122094: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3402225000 Hz\n",
      "2023-03-03 10:29:11.122664: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e778d6a170 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2023-03-03 10:29:11.122680: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 3s 48us/sample - loss: 0.0752 - val_loss: 0.0491\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 0.0426 - val_loss: 0.0364\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 0.0333 - val_loss: 0.0296\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 0.0281 - val_loss: 0.0259\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 0.0254 - val_loss: 0.0240\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 0.0236 - val_loss: 0.0223\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 0.0222 - val_loss: 0.0214\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 0.0212 - val_loss: 0.0204\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 0.0204 - val_loss: 0.0198\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 0.0197 - val_loss: 0.0190\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 0.0191 - val_loss: 0.0185\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 0.0185 - val_loss: 0.0180\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 0.0180 - val_loss: 0.0176\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 0.0176 - val_loss: 0.0172\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 0.0172 - val_loss: 0.0168\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 3s 48us/sample - loss: 0.0168 - val_loss: 0.0166\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 3s 48us/sample - loss: 0.0166 - val_loss: 0.0163\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 0.0163 - val_loss: 0.0160\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 0.0160 - val_loss: 0.0158\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 0.0158 - val_loss: 0.0156\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 0.0156 - val_loss: 0.0154\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 3s 50us/sample - loss: 0.0153 - val_loss: 0.0152\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 0.0152 - val_loss: 0.0151\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 3s 50us/sample - loss: 0.0150 - val_loss: 0.0149\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 0.0148 - val_loss: 0.0147\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 3s 50us/sample - loss: 0.0146 - val_loss: 0.0146\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 3s 51us/sample - loss: 0.0145 - val_loss: 0.0145\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 3s 50us/sample - loss: 0.0144 - val_loss: 0.0143\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 3s 50us/sample - loss: 0.0142 - val_loss: 0.0142\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 3s 51us/sample - loss: 0.0141 - val_loss: 0.0141\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 3s 51us/sample - loss: 0.0140 - val_loss: 0.0140\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 3s 50us/sample - loss: 0.0139 - val_loss: 0.0140\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 3s 51us/sample - loss: 0.0137 - val_loss: 0.0138\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 3s 51us/sample - loss: 0.0136 - val_loss: 0.0138\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 3s 51us/sample - loss: 0.0135 - val_loss: 0.0137\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 3s 51us/sample - loss: 0.0134 - val_loss: 0.0136\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.0133 - val_loss: 0.0134\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 3s 51us/sample - loss: 0.0132 - val_loss: 0.0134\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 3s 51us/sample - loss: 0.0131 - val_loss: 0.0134\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 3s 51us/sample - loss: 0.0131 - val_loss: 0.0133\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.0130 - val_loss: 0.0132\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 3s 51us/sample - loss: 0.0129 - val_loss: 0.0132\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.0128 - val_loss: 0.0131\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.0127 - val_loss: 0.0131\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.0127 - val_loss: 0.0130\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.0126 - val_loss: 0.0129\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.0125 - val_loss: 0.0129\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.0125 - val_loss: 0.0128\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.0124 - val_loss: 0.0128\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.0123 - val_loss: 0.0128\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "train_x = x_train.reshape(60000, 784) / 255\n",
    "val_x = x_test.reshape(10000, 784) / 255\n",
    "\n",
    "autoencoder = Sequential()\n",
    "autoencoder.add(Dense(512,  activation='elu', input_shape=(784,)))\n",
    "autoencoder.add(Dense(128,  activation='elu'))\n",
    "autoencoder.add(Dense(10,    activation='linear', name=\"bottleneck\"))\n",
    "autoencoder.add(Dense(128,  activation='elu'))\n",
    "autoencoder.add(Dense(512,  activation='elu'))\n",
    "autoencoder.add(Dense(784,  activation='sigmoid'))\n",
    "autoencoder.compile(loss='mean_squared_error', optimizer = Adam())\n",
    "trained_model = autoencoder.fit(train_x, train_x, batch_size=1024, epochs=50, verbose=1, validation_data=(val_x, val_x))\n",
    "encoder = Model(autoencoder.input, autoencoder.get_layer('bottleneck').output)\n",
    "encoded_data = encoder.predict(train_x)  # bottleneck representation\n",
    "decoded_output = autoencoder.predict(train_x)        # reconstruction\n",
    "encoding_dim = 10\n",
    "\n",
    "# return the decoder\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "decoder = autoencoder.layers[-3](encoded_input)\n",
    "decoder = autoencoder.layers[-2](decoder)\n",
    "decoder = autoencoder.layers[-1](decoder)\n",
    "decoder = Model(encoded_input, decoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG=x_test[181]\n",
    "IMG.shape\n",
    "import numpy as np\n",
    "IMG=IMG+np.random.randint(0,50,size=(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17.723295]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from tensorflow.keras.preprocessing import image\n",
    "# if the img.png is not one of the MNIST dataset that the model was trained on, the error will be very high.\n",
    "img = image.load_img(\"../../datasets/cat.jpg\", target_size=(28, 28), color_mode = \"grayscale\")\n",
    "#img = IMG\n",
    "input_img = image.img_to_array(img)/255\n",
    "#input_img=train_x[119]\n",
    "#input_img=val_x[181]\n",
    "inputs = input_img.reshape(1,784)\n",
    "target_data = autoencoder.predict(inputs)\n",
    "dist = np.linalg.norm(inputs - target_data, axis=-1)\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ishanu/ZED/Research/course_notes/notebooks/vae\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff7d3bb8790>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pylab as plt\n",
    "plt.imshow(x_test[181])\n",
    "#import seaborn as sns\n",
    "#sns.heatmap(input_img)\n",
    "#plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
