{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful Snippets: (including notebook links)\n",
    "---\n",
    "\n",
    "### Down-sampling images\n",
    "```\n",
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread('your_image.jpg')\n",
    "res = cv2.resize(img, dsize=(32, 32), interpolation=cv2.INTER_CUBIC)\n",
    "```\n",
    "\n",
    "### Consider the model definition steps:\n",
    "    \n",
    "```\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(64, 64, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(3,activation=tf.nn.softmax))\n",
    "```\n",
    "\n",
    "\n",
    "### Using custom metrics with keras\n",
    "\n",
    "```\n",
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "\n",
    "\n",
    "### compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc',f1_m,precision_m, recall_m])\n",
    "\n",
    "### fit the model\n",
    "history = model.fit(Xtrain, ytrain, validation_split=0.3, epochs=10, verbose=0)\n",
    "\n",
    "### evaluate the model\n",
    "loss, accuracy, f1_score, precision, recall = model.evaluate(Xtest, ytest, verbose=0)\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# Questions:\n",
    "---\n",
    "\n",
    "## Example notebook : \n",
    "https://github.com/zeroknowledgediscovery/course_notes/blob/master/notebooks/NN/CNN_example_3.ipynb\n",
    "\n",
    "\n",
    "## Question Set 1:\n",
    "\n",
    "Use the example keras script above to implement and validate\n",
    "6-class classifier for the following classes:\n",
    "+ AbdomenCT  \n",
    "+ BreastMRI  \n",
    "+ ChestCT  \n",
    "+ CXR  \n",
    "+ Hand  \n",
    "+ HeadCT\n",
    "where the images are given in the directory: \n",
    "https://github.com/zeroknowledgediscovery/course_notes/tree/master/datasets/med_MNIST\n",
    "\n",
    "**Note** Use a random sample of 80% of the images for training, and 20% for validation. \n",
    "\n",
    "---\n",
    "\n",
    "## Question Set 2:\n",
    "\n",
    "   a. What does **sequential** mean? Can it be anything else?\n",
    "   + Hint: https://keras.io/api/models/sequential/\n",
    "   \n",
    "   b. If the figures were sampled to be **32x32**, how would the model definition change? To demonstrate that you are indeed correct, `downsample` the image data to **32x32** and resolve the problem.\n",
    "   c. Explain what the numbers in **Conv2D(64, (3, 3),** mean\n",
    "   d. Compare performance variation when you choose `tanh` and `sigmoid` activation instead of `relu` in the convolutional layers\n",
    "   e. Why do you need the **Flatten** layer?\n",
    "   f. Why do you need the `softmax` activation in the last layer?\n",
    "   g. Investigate the performance change/loss when you do not use the convolution layers.\n",
    "- Hint:\n",
    "\n",
    "            model = models.Sequential()\n",
    "            model.add(layers.Flatten())\n",
    "            model.add(layers.Dense(128, activation='relu'))\n",
    "            model.add(layers.Dense(64, activation='relu'))\n",
    "            model.add(layers.Dense(3,activation=tf.nn.softmax))    \n",
    "   \n",
    "h. Please plot the variation of out of sample (validation) accuracy as a function of the number of epochs.\n",
    "i. Please investigate the variation of performance when you use different optimizers (other than `Adam`). \n",
    "+ Hint: https://keras.io/api/optimizers/\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Question Set 3\n",
    "\n",
    "### Classifying normal and cancer cells\n",
    "\n",
    "\n",
    " https://wiki.cancerimagingarchive.net/display/Public/C_NMC_2019+Dataset%3A+ALL+Challenge+dataset+of+ISBI+2019#52758223171ba531f[â€¦]29b21d3647e95f532c\n",
    " \n",
    "\n",
    "### Example notebook: https://github.com/zeroknowledgediscovery/course_notes/blob/master/notebooks/NN/CNN_example_3a.ipynb \n",
    " \n",
    " \n",
    "The data set (or a part of it) is already uploaded at `datasets/cells` (it is a tarball, and you need to access it with `git lfs pull`)\n",
    " \n",
    "The objective of this task is to maximize your validation F1-accuracy  (see snippet)\n",
    "\n",
    "The leader board F1-accuracy in the baove link is ~ 93\\%. Can you get close?\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
